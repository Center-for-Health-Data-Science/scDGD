{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training scDGD\n",
    "## An example on the 10x mouse brain 5k data set\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#!pip install anndata\n",
    "import anndata as ad\n",
    "#!pip install scanpy\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install scDGD from the repository\n",
    "!pip install git+https://github.com/Center-for-Health-Data-Science/scDGD\n",
    "from scDGD.classes import GaussianMixture\n",
    "from scDGD.models import DGD\n",
    "from scDGD.functions import prepate_data, dgd_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# define desired hyperparameters\n",
    "###\n",
    "latent_dim = 20\n",
    "n_epochs = 500\n",
    "\n",
    "# define which feature should be observed in clustering (e.g. cell type or disease state)\n",
    "adata_label_column_name = 'cell_type'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the example anndata file\n",
    "data_path = './data/'\n",
    "!wget -P data https://zenodo.org/record/7993711/files/adata.h5ad\n",
    "adata = ad.read(data_path+'adata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for training (and testing)\n",
    "adata, trainloader, validationloader, testloader = prepate_data(\n",
    "    adata,\n",
    "    label_column=adata_label_column_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of unique cell types as an initial guess for the number of clusters\n",
    "labels = trainloader.dataset.get_labels()\n",
    "n_celltypes = len(np.unique(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(Nmix=n_celltypes, dim=latent_dim)\n",
    "model = DGD(out=trainloader.dataset.n_genes, latent=latent_dim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running in the notebook, you can analyze the performance based on the returned history dataframe\n",
    "\n",
    "model, rep, test_rep, gmm, history = dgd_train(\n",
    "    model, gmm, trainloader, validationloader, n_epochs=n_epochs,\n",
    "    export_dir='./', export_name='scDGD'\n",
    ")\n",
    "\n",
    "# but it can also be run with logging to wandb (https://wandb.ai/) for more better monitoring and good project organization\n",
    "'''\n",
    "wandb.init(id=id, project=\"project_name\", entity=\"your_userID\")\n",
    "wandb.run.name = \"model_name\"\n",
    "wandb.run.save()\n",
    "\n",
    "model, rep, test_rep, gmm, history = dgd_train(\n",
    "    model, gmm, trainloader, validationloader, n_epochs=n_epochs,\n",
    "    export_dir='./', export_name='scDGD',\n",
    "    wandb_logging=True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstruction losses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['epoch'], history['train_recon_loss'], label='train')\n",
    "plt.plot(history['epoch'], history['test_recon_loss'], label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('reconstruction loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream use\n",
    "\n",
    "The learned representation can be added to the anndata object and then one can continue as usual with scanpy tools like UMAP visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add the representation to the anndata object\n",
    "# and then continue as usual with scanpy visualization and analysis\n",
    "\n",
    "adata_train = adata.copy()[adata.obs['train_val_test']=='train']\n",
    "adata_train.obsm['Latent'] = rep.z.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scanpy umap of the latent space colored by cell type\n",
    "sc.pp.neighbors(adata_train, use_rep='Latent')\n",
    "sc.tl.umap(adata_train)\n",
    "sc.pl.umap(adata_train, color=adata_label_column_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
